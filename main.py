import argparse
import os
import readline
import shutil
import warnings
from typing import List, Optional

os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
# å¿½ç•¥ä¸€äº›åº“çš„è­¦å‘Šä¿¡æ¯ï¼Œä¿æŒè¾“å‡ºæ•´æ´
warnings.filterwarnings("ignore")

import chromadb
from chromadb.utils import embedding_functions
import pdfplumber
from PIL import Image
from sentence_transformers import SentenceTransformer, util
import torch
from tqdm import tqdm

# ==========================================
# é…ç½®ä¸å¸¸é‡
# ==========================================
DB_PATH = "./chroma_db"
LIBRARY_PATH = "./my_papers"  # è®ºæ–‡è‡ªåŠ¨å½’æ¡£çš„æ ¹ç›®å½•
TEXT_MODEL_NAME = "all-MiniLM-L6-v2"  # è½»é‡çº§æ–‡æœ¬æ¨¡å‹
CLIP_MODEL_NAME = "clip-ViT-B-32"  # CLIP å›¾åƒæ¨¡å‹


class LocalAIAgent:
    def __init__(self):
        print("æ­£åœ¨åˆå§‹åŒ– AI Agent (åŠ è½½æ¨¡å‹ä¸æ•°æ®åº“)...")

        # 1. åˆå§‹åŒ– ChromaDB (æŒä¹…åŒ–å­˜å‚¨)
        self.client = chromadb.PersistentClient(path=DB_PATH)

        # 2. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ (ä½¿ç”¨ SentenceTransformers)
        # æ–‡æœ¬æ¨¡å‹
        self.text_model = SentenceTransformer(TEXT_MODEL_NAME)
        # å›¾åƒæ¨¡å‹ (CLIP)
        self.clip_model = SentenceTransformer(CLIP_MODEL_NAME)

        # 3. è·å–æˆ–åˆ›å»ºé›†åˆ (Collections)
        # æ³¨æ„ï¼šChromaDB åŸç”Ÿæ”¯æŒ embedding functionï¼Œä½†ä¸ºäº†çµæ´»æ€§æˆ‘ä»¬æ‰‹åŠ¨è®¡ç®— embedding
        self.paper_collection = self.client.get_or_create_collection(name="papers")
        self.image_collection = self.client.get_or_create_collection(name="images")

        # ç¡®ä¿å½’æ¡£ç›®å½•å­˜åœ¨
        if not os.path.exists(LIBRARY_PATH):
            os.makedirs(LIBRARY_PATH)

    # ==========================================
    # æ ¸å¿ƒåŠŸèƒ½ï¼šè®ºæ–‡ç®¡ç†
    # ==========================================
    def _extract_text_from_pdf(self, pdf_path: str, max_chars: int = 2000) -> str:
        """è¯»å–PDFå‰å‡ é¡µçš„æ–‡æœ¬ç”¨äºç´¢å¼•å’Œåˆ†ç±»"""
        text = ""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages[:5]:  # é€šå¸¸æ‘˜è¦å’Œå¼•è¨€åœ¨å‰2é¡µ
                    extracted = page.extract_text()
                    if extracted:
                        text += extracted + "\n"
            return text[:max_chars]  # æˆªå–å‰Nä¸ªå­—ç¬¦ï¼Œé¿å…Tokenæº¢å‡º
        except Exception as e:
            print(f"è¯»å– PDF å¤±è´¥ {pdf_path}: {e}")
            return ""

    def _classify_text(self, text: str, topics: List[str]) -> str:
        """é›¶æ ·æœ¬åˆ†ç±»ï¼šè®¡ç®—æ–‡æœ¬ä¸Topicçš„ç›¸ä¼¼åº¦ï¼Œè¿”å›æœ€åŒ¹é…çš„Topic"""
        if not topics or not text:
            return "Uncategorized"

        # ç¼–ç æ–‡æœ¬å’ŒTopics
        text_emb = self.text_model.encode(text, convert_to_tensor=True)
        topic_embs = self.text_model.encode(topics, convert_to_tensor=True)

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        cos_scores = util.cos_sim(text_emb, topic_embs)[0]
        best_idx = torch.argmax(cos_scores).item()

        return topics[best_idx]

    def add_paper(self, file_path: str, topics: Optional[str] = None):
        """æ·»åŠ è®ºæ–‡ï¼šæå–æ–‡æœ¬ -> å­˜å…¥å‘é‡åº“ -> (å¯é€‰)è‡ªåŠ¨åˆ†ç±»ç§»åŠ¨"""
        if not os.path.exists(file_path):
            print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
            return

        print(f"æ­£åœ¨å¤„ç†: {os.path.basename(file_path)}...")

        # 1. æå–æ–‡æœ¬
        content = self._extract_text_from_pdf(file_path)
        if not content:
            return

        # 2. ç”ŸæˆåµŒå…¥å¹¶å­˜å…¥æ•°æ®åº“
        embedding = self.text_model.encode(content).tolist()
        file_name = os.path.basename(file_path)

        self.paper_collection.upsert(
            ids=[file_name],
            documents=[content],
            metadatas=[{"filename": file_name, "path": file_path}],
            embeddings=[embedding]
        )
        print(f"âœ… å·²ç´¢å¼•: {file_name}")

        # 3. è‡ªåŠ¨åˆ†ç±»ä¸ç§»åŠ¨ (å¦‚æœæŒ‡å®šäº† topics)
        if topics:
            topic_list = [t.strip() for t in topics.split(',')]
            category = self._classify_text(content, topic_list)

            # åˆ›å»ºåˆ†ç±»æ–‡ä»¶å¤¹
            target_dir = os.path.join(LIBRARY_PATH, category)
            if not os.path.exists(target_dir):
                os.makedirs(target_dir)

            # ç§»åŠ¨æ–‡ä»¶
            target_path = os.path.join(target_dir, file_name)
            shutil.move(file_path, target_path)

            # æ›´æ–°æ•°æ®åº“ä¸­çš„è·¯å¾„ä¿¡æ¯
            self.paper_collection.update(
                ids=[file_name],
                metadatas=[{"filename": file_name, "path": target_path, "category": category}]
            )
            print(f"ğŸ“‚ å·²å½’æ¡£åˆ°: {category}/")

    def search_paper(self, query: str, n_results: int = 3):
        """è¯­ä¹‰æœç´¢è®ºæ–‡"""
        print(f"ğŸ” æ­£åœ¨æœç´¢æ–‡çŒ®: '{query}'...")
        query_emb = self.text_model.encode(query).tolist()

        results = self.paper_collection.query(
            query_embeddings=[query_emb],
            n_results=n_results
        )

        print("\n--- æœç´¢ç»“æœ ---")
        if not results['ids'][0]:
            print("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
            return

        for i, doc_id in enumerate(results['ids'][0]):
            meta = results['metadatas'][0][i]
            dist = results['distances'][0][i]
            print(f"[{i + 1}] æ–‡ä»¶å: {doc_id}")
            print(f"    è·¯å¾„: {meta.get('path', 'Unknown')}")
            print(f"    åˆ†ç±»: {meta.get('category', 'N/A')}")
            print(f"    ç›¸å…³æ€§è·ç¦»: {dist:.4f}")
            print("-" * 30)

    def organize_folder(self, source_folder: str, topics: str):
        """æ‰¹é‡æ•´ç†æ–‡ä»¶å¤¹"""
        if not os.path.exists(source_folder):
            print("æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
            return

        files = [f for f in os.listdir(source_folder) if f.lower().endswith('.pdf')]
        print(f"å‘ç° {len(files)} ä¸ª PDF æ–‡ä»¶ï¼Œå‡†å¤‡æ•´ç†...")

        for f in tqdm(files):
            full_path = os.path.join(source_folder, f)
            self.add_paper(full_path, topics)

    # ==========================================
    # æ ¸å¿ƒåŠŸèƒ½ï¼šå›¾åƒç®¡ç† (ä»¥æ–‡æœå›¾)
    # ==========================================
    def add_image(self, image_path: str):
        """æ·»åŠ å›¾ç‰‡ç´¢å¼•"""
        try:
            img = Image.open(image_path)
            # CLIP ç¼–ç å›¾ç‰‡
            embedding = self.clip_model.encode(img).tolist()
            file_name = os.path.basename(image_path)

            self.image_collection.upsert(
                ids=[file_name],
                embeddings=[embedding],
                metadatas=[{"path": image_path}]
            )
            print(f"âœ… å›¾ç‰‡å·²ç´¢å¼•: {file_name}")
        except Exception as e:
            print(f"å¤„ç†å›¾ç‰‡å¤±è´¥ {image_path}: {e}")

    def search_image(self, query: str, n_results: int = 3):
        """ä»¥æ–‡æœå›¾"""
        print(f"ğŸ–¼ï¸ æ­£åœ¨æœç´¢å›¾ç‰‡: '{query}'...")
        # CLIP ç¼–ç æ–‡æœ¬ (å› ä¸º CLIP æ˜¯å¤šæ¨¡æ€å¯¹é½çš„ï¼Œæ–‡æœ¬å’Œå›¾ç‰‡åœ¨åŒä¸€ç©ºé—´)
        query_emb = self.clip_model.encode(query).tolist()

        results = self.image_collection.query(
            query_embeddings=[query_emb],
            n_results=n_results
        )

        print("\n--- å›¾ç‰‡æœç´¢ç»“æœ ---")
        if not results['ids'][0]:
            print("æœªæ‰¾åˆ°ç›¸å…³å›¾ç‰‡ã€‚")
            return

        for i, doc_id in enumerate(results['ids'][0]):
            meta = results['metadatas'][0][i]
            print(f"[{i + 1}] å›¾ç‰‡: {doc_id}")
            print(f"    è·¯å¾„: {meta.get('path')}")
            print("-" * 30)

    def batch_add_images(self, folder_path: str):
        """æ‰¹é‡æ·»åŠ å›¾ç‰‡"""
        valid_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
        files = [f for f in os.listdir(folder_path) if os.path.splitext(f)[1].lower() in valid_exts]

        print(f"æ­£åœ¨ç´¢å¼• {len(files)} å¼ å›¾ç‰‡...")
        for f in tqdm(files):
            self.add_image(os.path.join(folder_path, f))


# ==========================================
# å‘½ä»¤è¡Œæ¥å£ (CLIP)
# ==========================================
def main():
    parser = argparse.ArgumentParser(description="Local Multimodal AI Agent")
    subparsers = parser.add_subparsers(dest="command", help="Available commands")

    # Command: add_paper
    parser_add = subparsers.add_parser("add_paper", help="Add and classify a paper")
    parser_add.add_argument("path", type=str, help="Path to PDF file")
    parser_add.add_argument("--topics", type=str, help="Comma separated topics (e.g., 'CV,NLP,RL')")

    # Command: search_paper
    parser_search = subparsers.add_parser("search_paper", help="Semantic search for papers")
    parser_search.add_argument("query", type=str, help="Search query")

    # Command: organize
    parser_org = subparsers.add_parser("organize", help="Batch organize a folder")
    parser_org.add_argument("folder", type=str, help="Folder containing PDFs")
    parser_org.add_argument("--topics", type=str, required=True, help="Topics for classification")

    # Command: add_image_folder
    parser_img_add = subparsers.add_parser("index_images", help="Index a folder of images")
    parser_img_add.add_argument("folder", type=str, help="Folder path")

    # Command: search_image
    parser_img_search = subparsers.add_parser("search_image", help="Text to Image search")
    parser_img_search.add_argument("query", type=str, help="Description of image")

    # æ·»åŠ ä¸€ä¸ªæ–°çš„å­å‘½ä»¤ 'interactive'
    parser_interactive = subparsers.add_parser("interactive", help="Run in interactive mode")

    args = parser.parse_args()

    # å¦‚æœæ˜¯äº¤äº’æ¨¡å¼
    if args.command == "interactive":
        agent = LocalAIAgent()  # åªåˆå§‹åŒ–ä¸€æ¬¡
        print("\n=== è¿›å…¥äº¤äº’æ¨¡å¼ (è¾“å…¥ 'exit' é€€å‡º) ===")
        print("æ”¯æŒå‘½ä»¤: search_paper <query> | search_image <query> | add_paper <path>")

        while True:
            user_input = input("\n(LocalAI) >>> ").strip()
            if user_input in ["exit", "quit"]:
                break

            # ç®€å•çš„å‘½ä»¤è§£æ
            parts = user_input.split(" ", 1)
            cmd = parts[0]
            param = parts[1] if len(parts) > 1 else ""

            if cmd == "search_paper":
                agent.search_paper(param)
            elif cmd == "search_image":
                agent.search_image(param)
            elif cmd == "add_paper":
                agent.add_paper(param)
            else:
                print("æœªçŸ¥å‘½ä»¤ï¼Œè¯·é‡è¯•ã€‚")

    # åŸæœ‰çš„å‘½ä»¤è¡Œé€»è¾‘
    elif args.command:
        agent = LocalAIAgent()

        if args.command == "add_paper":
            agent.add_paper(args.path, args.topics)
        elif args.command == "search_paper":
            agent.search_paper(args.query)
        elif args.command == "organize":
            agent.organize_folder(args.folder, args.topics)
        elif args.command == "index_images":
            agent.batch_add_images(args.folder)
        elif args.command == "search_image":
            agent.search_image(args.query)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()